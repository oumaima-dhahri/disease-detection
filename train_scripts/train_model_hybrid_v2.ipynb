{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ece5aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import time\n",
    "import cv2\n",
    "from typing import Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "DATASET_DIR = '../dataset'\n",
    "SAVE_DIR = '../saved_models_and_data'\n",
    "SPLIT_OUTPUT_DIR = '../dataset_split'\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16  # Reduced due to memory requirements\n",
    "TEST_SIZE = 0.15\n",
    "VAL_SIZE = 0.15\n",
    "EPOCHS = 10\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "USE_MIXED_PRECISION = True if torch.cuda.is_available() else False\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(SPLIT_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Preprocessing Functions\n",
    "# -----------------------------\n",
    "def canny_edge_detection(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply Canny edge detection\"\"\"\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "    return cv2.Canny(gray, 100, 200)\n",
    "\n",
    "def gaussian_blur_filter(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply Gaussian blur\"\"\"\n",
    "    return cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "def laplace_filter(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply Laplacian filter\"\"\"\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    return np.uint8(np.absolute(laplacian))\n",
    "\n",
    "def high_pass_filter(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply high-pass filter using FFT\"\"\"\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "    # Apply FFT\n",
    "    f_transform = np.fft.fft2(gray)\n",
    "    f_shift = np.fft.fftshift(f_transform)\n",
    "    # Create high-pass filter\n",
    "    rows, cols = gray.shape\n",
    "    crow, ccol = rows // 2, cols // 2\n",
    "    mask = np.ones((rows, cols), np.uint8)\n",
    "    r = 30  # Radius for high-pass filter\n",
    "    center = [crow, ccol]\n",
    "    x, y = np.ogrid[:rows, :cols]\n",
    "    mask_area = (x - center[0]) ** 2 + (y - center[1]) ** 2 <= r*r\n",
    "    mask[mask_area] = 0\n",
    "    # Apply mask\n",
    "    f_shift_filtered = f_shift * mask\n",
    "    f_ishift = np.fft.ifftshift(f_shift_filtered)\n",
    "    img_back = np.fft.ifft2(f_ishift)\n",
    "    img_back = np.abs(img_back)\n",
    "    # Normalize\n",
    "    img_back = ((img_back - img_back.min()) / (img_back.max() - img_back.min()) * 255).astype(np.uint8)\n",
    "    return img_back\n",
    "\n",
    "def apply_preprocessing(img: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Apply all preprocessing techniques\"\"\"\n",
    "    # Convert PIL to numpy if needed\n",
    "    if isinstance(img, Image.Image):\n",
    "        img = np.array(img)\n",
    "    # Apply preprocessing techniques\n",
    "    canny = canny_edge_detection(img)\n",
    "    gaussian = gaussian_blur_filter(img)\n",
    "    laplace = laplace_filter(img)\n",
    "    hpf = high_pass_filter(img)\n",
    "    return canny, gaussian, laplace, hpf\n",
    "\n",
    "# -----------------------------\n",
    "# Simplified Hybrid Model\n",
    "# -----------------------------\n",
    "class HybridModel(nn.Module):\n",
    "    \"\"\"Simplified Hybrid Model using pre-trained models\"\"\"\n",
    "    def __init__(self, num_classes=12):\n",
    "        super().__init__()\n",
    "        # Use pre-trained models for better performance\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.efficientnet = models.efficientnet_b0(pretrained=True)\n",
    "        # Remove the final classification layers\n",
    "        self.resnet_features = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        self.efficientnet_features = nn.Sequential(*list(self.efficientnet.children())[:-1])\n",
    "        # Fusion layer\n",
    "        resnet_features = 2048  # ResNet50 features\n",
    "        efficientnet_features = 1280  # EfficientNet-B0 features\n",
    "        fusion_dim = 512\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(resnet_features + efficientnet_features, fusion_dim),\n",
    "            nn.LayerNorm(fusion_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        # Final classifier\n",
    "        self.classifier = nn.Linear(fusion_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        # Extract features from both models\n",
    "        resnet_features = self.resnet_features(x).flatten(1)\n",
    "        efficientnet_features = self.efficientnet_features(x).flatten(1)\n",
    "        # Fusion\n",
    "        combined_features = torch.cat([resnet_features, efficientnet_features], dim=1)\n",
    "        fused_features = self.fusion(combined_features)\n",
    "        # Classification\n",
    "        output = self.classifier(fused_features)\n",
    "        return output\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Dataset with Preprocessing\n",
    "# -----------------------------\n",
    "class WheatDiseaseDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, apply_preprocessing=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.apply_preprocessing = apply_preprocessing\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.samples = []\n",
    "        for target_class in self.classes:\n",
    "            class_dir = os.path.join(root_dir, target_class)\n",
    "            for img_file in os.listdir(class_dir):\n",
    "                path = os.path.join(class_dir, img_file)\n",
    "                self.samples.append((path, self.class_to_idx[target_class]))\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        path, target = self.samples[idx]\n",
    "        try:\n",
    "            image = Image.open(path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, target\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {path}: {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "# -----------------------------\n",
    "# Data Loading and Splitting\n",
    "# -----------------------------\n",
    "def get_data_loaders():\n",
    "    # Check if split exists\n",
    "    split_dirs = [os.path.join(SPLIT_OUTPUT_DIR, split) for split in ['train', 'val', 'test']]\n",
    "    split_exists = all(os.path.isdir(d) and len(os.listdir(d)) > 0 for d in split_dirs)\n",
    "    if split_exists:\n",
    "        print('Found existing split dataset. Loading splits...')\n",
    "        train_dataset = WheatDiseaseDataset(\n",
    "            os.path.join(SPLIT_OUTPUT_DIR, 'train'), \n",
    "            transform=train_transform, \n",
    "            apply_preprocessing=False\n",
    "        )\n",
    "        val_dataset = WheatDiseaseDataset(\n",
    "            os.path.join(SPLIT_OUTPUT_DIR, 'val'), \n",
    "            transform=test_transform, \n",
    "            apply_preprocessing=False\n",
    "        )\n",
    "        test_dataset = WheatDiseaseDataset(\n",
    "            os.path.join(SPLIT_OUTPUT_DIR, 'test'), \n",
    "            transform=test_transform, \n",
    "            apply_preprocessing=False\n",
    "        )\n",
    "    else:\n",
    "        print('No split dataset found. Splitting and saving images...')\n",
    "        full_dataset = WheatDiseaseDataset(DATASET_DIR, transform=None, apply_preprocessing=False)\n",
    "        generator = torch.Generator().manual_seed(42)\n",
    "        indices = torch.randperm(len(full_dataset), generator=generator).tolist()\n",
    "        train_size = int((1 - TEST_SIZE - VAL_SIZE) * len(full_dataset))\n",
    "        val_size = int(VAL_SIZE * len(full_dataset))\n",
    "        test_size = len(full_dataset) - train_size - val_size\n",
    "        train_indices = indices[:train_size]\n",
    "        val_indices = indices[train_size:train_size + val_size]\n",
    "        test_indices = indices[train_size + val_size:]\n",
    "        train_data = Subset(full_dataset, train_indices)\n",
    "        val_data = Subset(full_dataset, val_indices)\n",
    "        test_data = Subset(full_dataset, test_indices)\n",
    "        def save_split_images(dataset, indices, split_name):\n",
    "            print(f\"Saving images for split: {split_name}\")\n",
    "            for idx in indices:\n",
    "                path, label_idx = dataset.dataset.samples[idx]\n",
    "                class_name = dataset.dataset.classes[label_idx]\n",
    "                filename = os.path.basename(path)\n",
    "                dest_dir = os.path.join(SPLIT_OUTPUT_DIR, split_name, class_name)\n",
    "                os.makedirs(dest_dir, exist_ok=True)\n",
    "                dest_path = os.path.join(dest_dir, filename)\n",
    "                shutil.copyfile(path, dest_path)\n",
    "        save_split_images(train_data, train_indices, 'train')\n",
    "        save_split_images(val_data, val_indices, 'val')\n",
    "        save_split_images(test_data, test_indices, 'test')\n",
    "        print('Image splits saved.')\n",
    "        train_dataset = WheatDiseaseDataset(\n",
    "            os.path.join(SPLIT_OUTPUT_DIR, 'train'), \n",
    "            transform=train_transform, \n",
    "            apply_preprocessing=False\n",
    "        )\n",
    "        val_dataset = WheatDiseaseDataset(\n",
    "            os.path.join(SPLIT_OUTPUT_DIR, 'val'), \n",
    "            transform=test_transform, \n",
    "            apply_preprocessing=False\n",
    "        )\n",
    "        test_dataset = WheatDiseaseDataset(\n",
    "            os.path.join(SPLIT_OUTPUT_DIR, 'test'), \n",
    "            transform=test_transform, \n",
    "            apply_preprocessing=False\n",
    "        )\n",
    "    # Calculate class weights for balanced sampling\n",
    "    targets = [s[1] for s in train_dataset.samples]\n",
    "    class_counts = np.bincount(targets)\n",
    "    class_weights = 1. / class_counts\n",
    "    sample_weights = [class_weights[t] for t in targets]\n",
    "    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    print('Data loaders are ready.')\n",
    "    return train_loader, val_loader, test_loader, train_dataset.classes\n",
    "\n",
    "# -----------------------------\n",
    "# Training Function\n",
    "# -----------------------------\n",
    "def train_model(model, device, train_loader, val_loader, num_epochs=EPOCHS):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
    "    best_acc = 0.0\n",
    "    no_improvement_epochs = 0\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=USE_MIXED_PRECISION)\n",
    "    train_log = []\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_corrects.double() / len(val_loader.dataset)\n",
    "        scheduler.step(val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} | \"\n",
    "              f\"LR: {current_lr:.6f} | \"\n",
    "              f\"Time: {time.time()-start_time:.1f}s\")\n",
    "        train_log.append({\n",
    "            'epoch': epoch+1, \n",
    "            'train_loss': epoch_loss, \n",
    "            'train_acc': epoch_acc.item(), \n",
    "            'val_loss': val_loss, \n",
    "            'val_acc': val_acc.item(), \n",
    "            'lr': current_lr\n",
    "        })\n",
    "        # Early stopping\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), os.path.join(SAVE_DIR, \"best_hybrid_model.pth\"))\n",
    "            no_improvement_epochs = 0\n",
    "        else:\n",
    "            no_improvement_epochs += 1\n",
    "        if no_improvement_epochs >= EARLY_STOPPING_PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    print(\"Training completed.\")\n",
    "    return model, train_log\n",
    "\n",
    "# -----------------------------\n",
    "# Main Execution\n",
    "# -----------------------------\n",
    "def main():\n",
    "    print(\"Setting up image transformations...\")\n",
    "    global train_transform, test_transform\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    print('Loading data...')\n",
    "    train_loader, val_loader, test_loader, class_labels = get_data_loaders()\n",
    "    print('Data loaded. Classes:', class_labels)\n",
    "    print('Initializing hybrid model...')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = HybridModel(num_classes=len(class_labels)).to(device)\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print('Starting training...')\n",
    "    model, train_log = train_model(model, device, train_loader, val_loader)\n",
    "    print('Training complete. Evaluating on test set...')\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(os.path.join(SAVE_DIR, \"best_hybrid_model.pth\"), map_location=device))\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    print('Test set predictions complete. Generating confusion matrix...')\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix (Hybrid Model)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(SAVE_DIR, \"hybrid_model_confusion_matrix.png\"))\n",
    "    plt.show()\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_labels, digits=4))\n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), os.path.join(SAVE_DIR, \"wheat_disease_hybrid_model.pth\"))\n",
    "    print('Model saved to', os.path.join(SAVE_DIR, \"wheat_disease_hybrid_model.pth\"))\n",
    "    # Save training log\n",
    "    import json\n",
    "    with open(os.path.join(SAVE_DIR, \"hybrid_model_training_log.json\"), 'w') as f:\n",
    "        json.dump(train_log, f, indent=2)\n",
    "    print('Training log saved.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
