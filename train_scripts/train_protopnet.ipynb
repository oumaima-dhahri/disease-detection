{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f452a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "DATASET_DIR = '../dataset'\n",
    "SAVE_DIR = '../saved_models_and_data'\n",
    "SPLIT_OUTPUT_DIR = '../dataset_split'\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32  # Increased batch size for better GPU utilization\n",
    "TEST_SIZE = 0.15 # New: For dataset splitting\n",
    "VAL_SIZE = 0.15 # New: For dataset splitting\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "EARLY_STOPPING_PATIENCE = 5 # New: For early stopping\n",
    "PROTOTYPE_SHAPE = (128, 512, 1, 1)  # 128 prototypes, 512 channels, 1x1 spatial\n",
    "USE_MIXED_PRECISION = True if torch.cuda.is_available() else False # New: For mixed precision training\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(SPLIT_OUTPUT_DIR, exist_ok=True) # Ensure split directory exists\n",
    "\n",
    "# -----------------------------\n",
    "# Seed Setting\n",
    "# -----------------------------\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Sets the seed for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# -----------------------------\n",
    "# Transformations\n",
    "# -----------------------------\n",
    "print('Setting up image transformations for training and testing...')\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(), # Added from convnext\n",
    "    transforms.RandomRotation(45),    # Added from convnext\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), # Added from convnext\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "print('Image transformations are ready.')\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Dataset\n",
    "# -----------------------------\n",
    "print('Defining custom dataset class for wheat disease images...')\n",
    "class WheatDiseaseDataset(Dataset): # Changed from torch.utils.data.Dataset\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.samples = []\n",
    "        for target_class in self.classes:\n",
    "            class_dir = os.path.join(root_dir, target_class)\n",
    "            # Ensure it's a directory before listing\n",
    "            if os.path.isdir(class_dir):\n",
    "                for img_file in os.listdir(class_dir):\n",
    "                    path = os.path.join(class_dir, img_file)\n",
    "                    self.samples.append((path, self.class_to_idx[target_class]))\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        path, target = self.samples[idx]\n",
    "        try:\n",
    "            image = Image.open(path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, target\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du chargement de {path}: {e}\")\n",
    "            # Fallback: try to load the next image in the dataset to avoid stopping\n",
    "            # This might create bias if many images are corrupted consecutively\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "print('Custom dataset class defined.')\n",
    "\n",
    "# -----------------------------\n",
    "# Load and Split Dataset (Refactored)\n",
    "# -----------------------------\n",
    "print('Preparing data loaders and splitting dataset if needed...')\n",
    "def get_data_loaders():\n",
    "    split_dirs = [os.path.join(SPLIT_OUTPUT_DIR, split) for split in ['train', 'val', 'test']]\n",
    "    # Check if split directories exist and are not empty\n",
    "    split_exists = all(os.path.isdir(d) and len(os.listdir(d)) > 0 for d in split_dirs)\n",
    "\n",
    "    if split_exists:\n",
    "        print('Found existing split dataset. Loading splits...')\n",
    "        train_dataset = WheatDiseaseDataset(os.path.join(SPLIT_OUTPUT_DIR, 'train'), transform=train_transform)\n",
    "        val_dataset = WheatDiseaseDataset(os.path.join(SPLIT_OUTPUT_DIR, 'val'), transform=test_transform)\n",
    "        test_dataset = WheatDiseaseDataset(os.path.join(SPLIT_OUTPUT_DIR, 'test'), transform=test_transform)\n",
    "    else:\n",
    "        print('No split dataset found. Splitting and saving images...')\n",
    "        full_dataset = WheatDiseaseDataset(DATASET_DIR, transform=None) # Use None transform for initial loading\n",
    "\n",
    "        generator = torch.Generator().manual_seed(42)\n",
    "        indices = torch.randperm(len(full_dataset), generator=generator).tolist()\n",
    "\n",
    "        train_size = int((1 - TEST_SIZE - VAL_SIZE) * len(full_dataset))\n",
    "        val_size = int(VAL_SIZE * len(full_dataset))\n",
    "        # test_size is implicitly the rest\n",
    "        # test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "        train_indices = indices[:train_size]\n",
    "        val_indices = indices[train_size:train_size + val_size]\n",
    "        test_indices = indices[train_size + val_size:]\n",
    "\n",
    "        # Create Subset objects for initial splitting (before saving to disk)\n",
    "        train_data_subset = Subset(full_dataset, train_indices)\n",
    "        val_data_subset = Subset(full_dataset, val_indices)\n",
    "        test_data_subset = Subset(full_dataset, test_indices)\n",
    "\n",
    "        def save_split_images(dataset_subset, split_name):\n",
    "            print(f\"Saving images for split: {split_name}\")\n",
    "            for idx_in_subset in range(len(dataset_subset)):\n",
    "                original_idx = dataset_subset.indices[idx_in_subset] # Get original index from subset\n",
    "                path, label_idx = full_dataset.samples[original_idx] # Use full_dataset to get original path\n",
    "                class_name = full_dataset.classes[label_idx]\n",
    "                filename = os.path.basename(path)\n",
    "                dest_dir = os.path.join(SPLIT_OUTPUT_DIR, split_name, class_name)\n",
    "                os.makedirs(dest_dir, exist_ok=True)\n",
    "                dest_path = os.path.join(dest_dir, filename)\n",
    "                shutil.copyfile(path, dest_path)\n",
    "\n",
    "        save_split_images(train_data_subset, 'train')\n",
    "        save_split_images(val_data_subset, 'val')\n",
    "        save_split_images(test_data_subset, 'test')\n",
    "        print('Image splits saved.')\n",
    "\n",
    "        # Now, load datasets with appropriate transforms from the new split directories\n",
    "        train_dataset = WheatDiseaseDataset(os.path.join(SPLIT_OUTPUT_DIR, 'train'), transform=train_transform)\n",
    "        val_dataset = WheatDiseaseDataset(os.path.join(SPLIT_OUTPUT_DIR, 'val'), transform=test_transform)\n",
    "        test_dataset = WheatDiseaseDataset(os.path.join(SPLIT_OUTPUT_DIR, 'test'), transform=test_transform)\n",
    "\n",
    "    print('Calculating class weights for balanced sampling...')\n",
    "    # Calculate class weights for the training set only\n",
    "    targets = [s[1] for s in train_dataset.samples]\n",
    "    class_counts = np.bincount(targets)\n",
    "    class_weights = 1. / class_counts\n",
    "    sample_weights = [class_weights[t] for t in targets]\n",
    "    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=0, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    print('Data loaders are ready.')\n",
    "    return train_loader, val_loader, test_loader, train_dataset.classes\n",
    "\n",
    "# ProtoPNet Model (No changes to the model architecture)\n",
    "# -----------------------------\n",
    "class ProtoPNet(nn.Module):\n",
    "    def __init__(self, base_model, prototype_shape, num_classes):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.prototype_shape = prototype_shape\n",
    "        self.num_prototypes = prototype_shape[0]\n",
    "        # Using nn.Parameter for learnable prototypes\n",
    "        self.prototype_vectors = nn.Parameter(torch.randn(prototype_shape), requires_grad=True)\n",
    "        # Last layer for classification\n",
    "        self.last_layer = nn.Linear(self.num_prototypes, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extraction\n",
    "        features = self.base_model(x)\n",
    "        # Calculate distances to prototypes\n",
    "        distances = self._l2_convolution(features)\n",
    "        # Global min-pooling over H, W\n",
    "        min_distances = torch.amin(distances, dim=(2, 3))  # [B, num_prototypes]\n",
    "        # Convert distances to similarity scores\n",
    "        prototype_activations = self.distance_2_similarity(min_distances)\n",
    "        # Final classification layer\n",
    "        logits = self.last_layer(prototype_activations)\n",
    "        return logits, distances, features\n",
    "\n",
    "    def _l2_convolution(self, x):\n",
    "        # Calculate squared L2 norm of feature map activations\n",
    "        x2 = torch.sum(x ** 2, dim=1, keepdim=True)\n",
    "        # Calculate squared L2 norm of prototype vectors\n",
    "        p2 = torch.sum(self.prototype_vectors ** 2, dim=(1, 2, 3))\n",
    "        p2 = p2.view(1, -1, 1, 1) # Reshape for broadcasting\n",
    "        # Reshape prototypes for convolution\n",
    "        prototypes = self.prototype_vectors.squeeze(-1).squeeze(-1)\n",
    "        # Calculate 2 * x * p component using convolution\n",
    "        xp = nn.functional.conv2d(x, weight=prototypes.unsqueeze(-1).unsqueeze(-1))\n",
    "        # Combine terms to get squared L2 distances\n",
    "        distances = x2 - 2 * xp + p2\n",
    "        return distances\n",
    "\n",
    "    def distance_2_similarity(self, distances):\n",
    "        # Convert distances to similarity (e.g., negative distance)\n",
    "        return -distances\n",
    "\n",
    "# -----------------------------\n",
    "# Training Function (Refactored)\n",
    "# -----------------------------\n",
    "def train_model(model, device, train_loader, val_loader, num_epochs=EPOCHS):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "    best_acc = 0.0\n",
    "    no_improvement_epochs = 0\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=USE_MIXED_PRECISION)\n",
    "    print(f\"Model device: {next(model.parameters()).device}\")\n",
    "    train_log = []\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION):\n",
    "                logits, _, _ = model(inputs)\n",
    "                loss = criterion(logits, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION):\n",
    "                    logits, _, _ = model(inputs)\n",
    "                    loss = criterion(logits, labels)\n",
    "\n",
    "                _, preds = torch.max(logits, 1)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_corrects.double() / len(val_loader.dataset)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} | LR: {current_lr:.6f} | Time: {time.time()-start_time:.1f}s\")\n",
    "\n",
    "        scheduler.step(val_loss) # Update learning rate based on validation loss\n",
    "\n",
    "        train_log.append({'epoch': epoch+1, 'train_loss': epoch_loss, 'train_acc': epoch_acc.item(),\n",
    "                           'val_loss': val_loss, 'val_acc': val_acc.item(), 'lr': current_lr})\n",
    "\n",
    "        # Save best model and early stopping\n",
    "        if val_acc > best_acc:\n",
    "            torch.save(model.state_dict(), os.path.join(SAVE_DIR, \"best_protopnet_model.pth\"))\n",
    "            best_acc = val_acc\n",
    "            no_improvement_epochs = 0\n",
    "        else:\n",
    "            no_improvement_epochs += 1\n",
    "\n",
    "        if no_improvement_epochs >= EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"Early stopping triggered after {no_improvement_epochs} epochs without improvement.\")\n",
    "            break\n",
    "\n",
    "    print(\"Entraînement ProtoPNet terminé.\")\n",
    "    print(f\"Meilleure précision de validation: {best_acc:.4f}\")\n",
    "    return model, train_log\n",
    "\n",
    "# -----------------------------\n",
    "# Main Execution\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print('Loading data...')\n",
    "    train_loader, val_loader, test_loader, class_labels = get_data_loaders()\n",
    "    NUM_CLASSES = len(class_labels)\n",
    "    print('Data loaded. Classes:', class_labels)\n",
    "\n",
    "    print('Initializing model...')\n",
    "    base_model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "    base_model = nn.Sequential(*list(base_model.children())[:-2])  # Remove avgpool & fc\n",
    "\n",
    "    model = ProtoPNet(base_model, PROTOTYPE_SHAPE, NUM_CLASSES)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    print(f\"Using device: {device}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "        print(f\"CUDA device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "\n",
    "    print('Model initialized. Starting training...')\n",
    "    model, train_log = train_model(model, device, train_loader, val_loader)\n",
    "    print('Training complete. Evaluating on test set...')\n",
    "\n",
    "    # Evaluation on Test Set (using the best saved model)\n",
    "    model.load_state_dict(torch.load(os.path.join(SAVE_DIR, \"best_protopnet_model.pth\"), map_location=device))\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits, _, _ = model(inputs)\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    print('Test set predictions complete. Generating confusion matrix...')\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.xlabel(\"Prédit\")\n",
    "    plt.ylabel(\"Réel\")\n",
    "    plt.title(\"Matrice de Confusion (ProtoPNet)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(SAVE_DIR, \"protopnet_confusion_matrix.png\")) # Save confusion matrix\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nRapport de classification:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_labels, digits=4))\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(SAVE_DIR, \"wheat_disease_protopnet_final_model.pth\"))\n",
    "    print('Model saved to', os.path.join(SAVE_DIR, \"wheat_disease_protopnet_final_model.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264f7e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype Visualization (Optional - uncomment to run)\n",
    "\n",
    "\n",
    "print(\"\\nStarting prototype visualization...\")\n",
    "save_prototype_visualizations(model, val_loader.dataset, save_dir=os.path.join(SAVE_DIR, \"protopnet_prototypes\"), num_prototypes=model.num_prototypes)\n",
    "print(\"Prototype visualization complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
